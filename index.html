<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!--We-Math-->
  <meta name="description"
        content="Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?">
  <meta name="keywords" content="We-Math">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>We-Math</title>
  <link rel="icon" href="./static/images/icon.png">

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <!--css file-->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">
  <!--html head icon-->
  <link rel="icon" href="./static/images/icon.png">


  <!--js file-->
  <script type="text/javascript" src="./static/js/sort-table.js" defer></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/leaderboard.js"></script>  
  <script src="./static/js/leaderboard_button.js"></script>
</head>

<!--start body-->
<body>
<!--nav content-->
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!--nav menu-->
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!--click-->
      <!--
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>-->
      <!--navbar link-->
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <!--<a class="navbar-item" href="https://github.com/RQ-Lab/OBS-Visual">-->
          <a class="navbar-item">
            Future Release
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>

<!--title author and link-->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!--main title-->
          <h1 class="title is-1 publication-title">
            <!--icon-->
            <img src="static/images/icon.png" style="width:1em; vertical-align: middle" alt="Logo"/> 
            <span class="wemath" style="vertical-align: middle">We-Math</span>            
          </h1>
          <!--subtitle-->
          <h2 class="subtitle is-3 publication-subtitle">
            Does Your Large Multimodal Model <br> Achieve Human-like Mathematical Reasoning?
          </h2>

          <!--author link-->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Runqi Qiao*<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Qiuna Tan*<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Guanting Dong<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Minhui Wu<sup style="color:#06D001;"><b>2</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Chong Sun<sup style="color:#06D001;"><b>2</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Xiaoshuai Song<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span><br>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Zhuoma GongQue<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Shanglin Lei<sup style="color:#FF8F00"><b>3</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Zhe Wei<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Miaoxuan Zhang<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Runfeng Qiao<sup style="color:#AF47D2;"><b>4</b></sup></a>,
            </span><br>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Yifan Zhang<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Xiao Zong<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Yida Xu<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Muxi Diao<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Zhimin Bao<sup style="color:#06D001;"><b>2</b></sup></a>,
            </span><br>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Chen Li<sup style="color:#06D001;"><b>2</b></sup></a>,
            </span>
            <span class="author-block">
              <a href="index.html" style="text-decoration: none; color: inherit;">Honggang Zhang‚Ä†<sup style="color:#4B70F5;"><b>1</b></sup></a>,
            </span>
          </div>
          
          <!--author institution-->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#4B70F5;"><b>1</b></sup>Beijing University of Posts and Telecommunications,</span>
            <span class="author-block"><sup style="color:#06D001;"><b>2</b></sup>Wechat, Tencent Inc.,</span>
            <span class="author-block"><sup style="color:#FF8F00"><b>3</b></sup>Huazhong University of Science and Technology,</span>
            <span class="author-block"><sup style="color:#AF47D2;"><b>4</b></sup>Beijing Institute of Technology</span>
          </div>
          
          <br>
          <!--equal contribution-->
          <div class="is-size-5 publication-authors">
            <span class="author-block">*Equal contribution</span><br>
            <span class="author-block">‚Ä†Corresponding author</span>
          </div>

          <!--links-->
          <div class="column has-text-centered">
            <div class="publication-links">
              <!--arxiv link-->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2407.01284"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!--
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-video"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/We-Math/We-Math"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Huggingface Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/We-Math/We-Math"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">ü§ó</p>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>

              <!-- Leaderboard Link.-->
              <span class="link-block">
                <a href="#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">üèÜ</p>
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>
              <!-- Twitter Link. -->
              <span class="link-block">
                <a href="https://x.com/Richard_qrq/status/1807965633570824218"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <img src="static/images/xicon.png">
                  </span>
                  <span>Twitter</span>
                </a>
              </span>
              <!--Examples Link-->
              <span class="link-block">
                <a href="#examples"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fas fa-book-open"></i>
                  </span>
                  <span>Knowledge Card</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!--overview of we-math-->
<section class="hero teaser">
  <div class="container is-max-desktop">
        <div class="content has-text-centered">
          <img src="static/images/fig2.png" width="100%"/>
          <p>
            Overview diagram and the statistics of<span class="wemath"> We-Math</span>.
            The left and right side shows the first two layers of <span class="wemath">We-Math</span>'s categories and information of different samples and terminal nodes.
          </p>
        </div>
    </div>
  </div>
</section>

<!---------------------------------main body-------------------------------------------->
<!-- Intro. -->
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>Inspired by human-like mathematical reasoning, we introduce <span class="wemath">We-Math</span>, 
             the first benchmark specifically designed to explore the problem-solving principles beyond the end-to-end performance. 
          </p>

          <p>
            We meticulously collect and categorize <b>6.5K</b> visual math problems, 
            spanning <b>67</b> hierarchical knowledge concepts and <b>5</b> layers of knowledge granularity. 
            We firstly decompose composite problems into sub-problems according to the required knowledge concepts and introduce a novel four-dimensional metric, 
            namely <b>Insufficient Knowledge (IK)</b>, <b>Inadequate Generalization (IG)</b>, <b>Complete Mastery (CM)</b>, and <b>Rote Memorization (RM)</b> to hierarchically assess inherent issues in LMMs' reasoning process.
          </p>
            
          <p>
            With <span class="wemath">We-Math</span>, we conduct a thorough evaluation of existing LMMs
            in visual mathematical reasoning and reveal a negative correlation between solving
            step and problem-specific performance. We confirm the <b>IK</b> issue of LMMs can
            be effectively improved via knowledge augmentation strategy. More notably, the
            primary challenge of <b>GPT-4o</b> has significantly transitioned from <b>IK</b> to <b>IG</b>, establishing 
            it as the first LMM advancing towards the knowledge generalization stage.
            In contrast, other LMMs exhibit a marked inclination towards <b>Rote Memorization</b>
            they correctly solve composite problems involving multiple knowledge concepts,
            yet fail in answering sub-problems. 
          </p>
          <p>  
          We anticipate that <span class="wemath">We-Math</span> will open new
            pathways for advancements in visual mathematical reasoning for LMMs.
          </p>
        </div>
        <br><br>
        <div class="content has-text-centered">
          <img src="static/images/fig1-3_res.png" width="100%"/>
          <p>
            Overview of LMMs' performances on <span class="wemath"> We-Math</span>. Figures from left to right illustrates the
            (1) accuracy of different LMMs on various problem-solving steps, (2) the performance in different
            visual mathematics categories and (3) the result in knowledge based reasoning evaluation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<!--benchmark section-->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 wemath">
      <img src="static/images/icon.png" style="width:1em;vertical-align: middle" alt="Logo"/>
      <span class="wemath" style="vertical-align: middle">We-Math Benchmark</span>
    </h1>
  </div>
</section>


<!---overview section-->
<section>
  <div class="container">
    <div class="columns is-centered has-text-centered m-6">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <!--overview of benchmark-->
          <p>
            Different from existing benchmarks,
            <span class="wemath">We-Math</span> is constructed around textbook knowledge units, 
            decomposing composite problem solutions into sub-problems based on the knowledge concepts.<br>
            <b>(1) Hierarchical Knowledge Structure.</b> Strictly adheres to the knowledge presented in mathematics textbooks, 
            featuring a rigorous hierarchical and multi-category architecture. It
            ensures the independence of knowledge concepts within the same level, while establishing logical
            relationships among concepts at different hierarchical levels.<br>
            <b>(2) Knowledge based Reasoning Evaluation.</b> To explore how LMMs solve
            problems. Drawing upon that humans tackle problems incrementally by leveraging fundamental
            knowledge concepts, we break down complex mathematical problems into more manageable sub105
            problems. Furthermore, we employ diverse measurement dimensions for meticulous evaluations.<br>
            <b>(3) Knowledge Concept Augmentation.</b> To alleviate the inherent issues during the problem-solving
            process, we heuristically introduce descriptions for <b>67 knowledge concepts</b> from Wikipedia and 
            textbooks, thereby providing essential knowledge support for the reasoning processes of LMMs.
          </p>
          <!--carousel-->
          <div id="overview-carousel" class="carousel results-carousel">
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/step_2.png" alt="algebraic reasoning" width="90%"/>
                <p> The pipeline of knowledge-based data decomposition (an example of a two-step problem in <span class="wemath" style="vertical-align: middle">We-Math</span>).</p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/step_3.png" alt="arithmetic reasoning" width="90%"/>
                <p> The pipeline of knowledge-based data decomposition (an example of a three-step problem in <span class="wemath" style="vertical-align: middle">We-Math</span>). </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section>
  <!--metric reasoning section-->
  <div class="container">
    <div class="columns is-centered has-text-centered m-6">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Metric for Reasoning Evaluation</h2>
        <div class="content has-text-justified">
          <p>
            Based on the decomposed multi-step problems, we further reveal the inherent issues of LMMs in problem-solving process. 
            We feed both the <i>M</i> one-step sub-problems and the original problem into LMMs, 
            and classifying the responses into four categories<br>
            <b>1. Insufficient Knowledge (IK)</b>: Part of one-step problems contain errors, and the multi-step problem
            is wrong. It is reasonable because model's insufficient grasp of single knowledge concept may lead
            to errors in multi-step problem.<br>
            <b>2. Inadequate Generalization (IG)</b>: One-Step problems are all correct, but the multi-step problem is
            incorrect. This is also considered reasonable. While LMMs are capable of understanding individual
            knowledge concepts, they may struggle to generalize that knowledge to solve composite problems.<br>
            <b>3. Complete Mastery (CM)</b>: One-Step problems are all correct, and multi-step problem is also
            answered correctly. This result demonstrates that the model's results are both reliable and accurate.<br>
            <b>4. Rote Memorization (RM)</b>: One-Step problems contain errors, but the multi-step problem is
            answered correctly, which contradicts human logical thinking. If a model can solve composite
            multi-step problems but fails to answer the one-step problems needed in the process, it raises doubts
            about the model's reliability.<br>
          </p>

          <!--metric result-->
          <div id="results-carousel" class="carousel results-carousel">
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/metric_2.png" width="100%"/>
                <p> An example of the four-dimensional metrics for evaluating a two-step problem, using both loose and strict settings.</p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/metric_3_strict.png" width="90%"/>
                <p> Diagram illustrating strict metric in three-step problem. </p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/metric_3_loose.png" width="90%"/>
                <p> Diagram illustrating loose metric in three-step problem. </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!----------------------------------Experiment Results----------------------------------------------->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 wemath">Experiment Results</h1>
  </div>
</section>


<!--leaderboard-->
<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3" id="leaderboard">Leaderboard on We-Math (testmini)</h2>
        <!--change in leaderboard_button.js-->
        <div class="content">
          <button id="toggleButton" onclick="changeButtonText()"><b style='font-size: larger;'>Metric Evaluation Leaderboard</b> (Click to Switch)</button>
          <p class="mt-3">Accuracy scores on the <b>testmini</b> subset (1,740 examples) of <img src="static/images/icon.png" style="width:1.0em;vertical-align: middle" alt="Logo"/>
            <span class="wemath">We-Math</span>.
          </p>
          <!--table name-->
          <table id="table1" class="js-sort-table">
            <tr>
              <td class="js-sort-number"><strong>#</strong></td>
              <td class="js-sort"><strong>Model</strong></td>
              <td class="js-sort"><strong>Source</strong></td>
              <td class="js-sort-date"><strong>Date</strong></td>
              <td class="js-sort-number"><strong>Avg(Strict)</strong></td>
              <td class="js-sort-number"><strong>IK(Strict)</strong></td>
              <td class="js-sort-number"><strong>IG(Strict)</strong></td>
              <td class="js-sort-number"><strong>CM(Strict)</strong></td>
              <td class="js-sort-number"><strong>RM(Strict)</strong></td>
              <td class="js-sort-number"><strong>Avg(Loose)</strong</td>
              <td class="js-sort-number"><strong>IK(Loose)</strong></td>
              <td class="js-sort-number"><strong>IG(Loose)</strong></td>
              <td class="js-sort-number"><strong>CM(Loose)</strong></td>
              <td class="js-sort-number"><strong>RM(Loose)</strong></td>
            </tr>
            <tr>
              <td>1</td>
              <td><b>GPT-4o ü•á</b></td>
              <td><a href="https://openai.com/index/hello-gpt-4o/" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td><b>42.86%</b></td>
              <td>31.24% (164)</td>
              <td>15.24% (80)</td>
              <td>35.24% (185)</td>
              <td>34.16% (96)</td>
              <td><b>60.57%</b></td>
              <td>31.24% (164)</td>
              <td>15.24% (80)</td>
              <td>52.95% (278)</td>
              <td>1.07% (3)</td>
            </tr>
            <tr>
              <td>2</td>
              <td><b>GPT-4V ü•à</b></td>
              <td><a href="https://openai.com/contributions/gpt-4v/" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-04</td>
              <td><b>31.05%</b></td>
              <td>39.81% (209)</td>
              <td>14.48% (76)</td>
              <td>23.81% (125)</td>
              <td>47.92% (115)</td>
              <td><b>51.43%</b></td>
              <td>39.81% (209)</td>
              <td>14.48% (76)</td>
              <td>44.19% (232)</td>
              <td>3.33% (8)</td>
            </tr>
            <tr>
              <td>3</td>
              <td><b>Gemini-1.5-pro ü•â</b></td>
              <td><a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td><b>26.38%</b></td>
              <td>42.86% (225)</td>
              <td>11.24% (59)</td>
              <td>20.76% (109)</td>
              <td>54.77% (132)</td>
              <td><b>46.00%</b></td>
              <td>42.86% (225)</td>
              <td>11.24% (59)</td>
              <td>40.38% (212)</td>
              <td>12.03% (29)</td>
            </tr>
            <tr>
              <td>4</td>
              <td><b>LLaVA-NeXT-110B</b></td>
              <td><a href="https://huggingface.co/lmms-lab/llava-next-110b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td><b>19.24%</b></td>
              <td>50.29% (264)</td>
              <td>14.48% (76)</td>
              <td>12.00% (63)</td>
              <td>65.95% (122)</td>
              <td><b>37.90%</b></td>
              <td>50.29% (264)</td>
              <td>14.48% (76)</td>
              <td>30.67% (161)</td>
              <td>12.97% (24)</td>
            </tr>
            <tr>
              <td>5</td>
              <td><b>InternVL-Chat-V1.5</b></td>
              <td><a href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-04</td>
              <td><b>14.95%</b></td>
              <td>56.19% (295)</td>
              <td>13.90% (73)</td>
              <td>8.00% (42)</td>
              <td>73.25% (115)</td>
              <td><b>32.67%</b></td>
              <td>56.19% (295)</td>
              <td>13.90% (73)</td>
              <td>25.71% (135)</td>
              <td>14.01% (22)</td>
            </tr>
            <tr>
              <td>6</td>
              <td><b>GLM-4V-9B</b></td>
              <td><a href="https://huggingface.co/THUDM/glm-4v-9b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-06</td>
              <td><b>14.86%</b></td>
              <td>52.95% (278)</td>
              <td>9.52% (50)</td>
              <td>10.10% (53)</td>
              <td>73.10% (144)</td>
              <td><b>35.05%</b></td>
              <td>52.95% (278)</td>
              <td>9.52% (50)</td>
              <td>30.29% (159)</td>
              <td>19.29% (38)</td>
            </tr>
            <tr>
              <td>7</td>
              <td><b>LLaVA-NeXT-72B</b></td>
              <td><a href="https://huggingface.co/lmms-lab/llava-next-72b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td><b>13.43%</b></td>
              <td>58.86% (309)</td>
              <td>7.05% (37)</td>
              <td>9.90% (52)</td>
              <td>70.95% (127)</td>
              <td><b>31.52%</b></td>
              <td>58.86% (309)</td>
              <td>7.05% (37)</td>
              <td>28.00% (147)</td>
              <td>17.88% (32)</td>
            </tr>
            <tr>
              <td>8</td>
              <td><b>InternLM-XComposer2-VL-7B</b></td>
              <td><a href="https://huggingface.co/internlm/internlm-xcomposer2-vl-7b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-04</td>
              <td><b>12.67%</b></td>
              <td>56.38% (296)</td>
              <td>10.48% (55)</td>
              <td>7.43% (39)</td>
              <td>77.59% (135)</td>
              <td><b>30.95%</b></td>
              <td>56.38% (296)</td>
              <td>10.48% (55)</td>
              <td>25.71% (135)</td>
              <td>22.41% (39)</td>
            </tr>
            <tr>
              <td>9</td>
              <td><b>LongVA</b></td>
              <td><a href="https://huggingface.co/lmms-lab/LongVA-7B" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-06</td>
              <td><b>11.52%</b></td>
              <td>61.14% (321)</td>
              <td>8.95% (47)</td>
              <td>7.05% (37)</td>
              <td>76.43% (120)</td>
              <td><b>27.71%</b></td>
              <td>61.14% (321)</td>
              <td>8.95% (47)</td>
              <td>23.24% (122)</td>
              <td>22.29% (35)</td>
            </tr>
            <tr>
              <td>10</td>
              <td><b>Phi3-Vision-4.2B</b></td>
              <td><a href="https://huggingface.co/microsoft/Phi-3-vision-128k-instruct" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td><b>10.57%</b></td>
              <td>58.86% (309)</td>
              <td>8.95% (47)</td>
              <td>6.10% (32)</td>
              <td>81.07% (137)</td>
              <td><b>29.81%</b></td>
              <td>58.86% (309)</td>
              <td>8.95% (47)</td>
              <td>25.33% (133)</td>
              <td>21.30% (36)</td>
            </tr>
            <tr>
              <td>11</td>
              <td><b>Qwen-VL-Max</b></td>
              <td><a href="https://github.com/QwenLM/Qwen-VL/tree/master" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-01</td>
              <td><b>10.48%</b></td>
              <td>65.14% (342)</td>
              <td>7.62% (40)</td>
              <td>6.67% (35)</td>
              <td>75.52% (108)</td>
              <td><b>25.52%</b></td>
              <td>65.14% (342)</td>
              <td>7.62% (40)</td>
              <td>21.71% (114)</td>
              <td>20.28% (29)</td>
            </tr>
            <tr>
              <td>12</td>
              <td><b>MiniCPM-LLaMA3-V 2.5</b></td>
              <td><a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td><b>9.52%</b></td>
              <td>60.19% (316)</td>
              <td>9.14% (48)</td>
              <td>4.95% (26)</td>
              <td>83.85% (135)</td>
              <td><b>28.00%</b></td>
              <td>60.19% (316)</td>
              <td>9.14% (48)</td>
              <td>23.43% (123)</td>
              <td>23.60% (38)</td>
            </tr>
            <tr>
              <td>13</td>
              <td><b>G-LLaVA-13B</b></td>
              <td><a href="https://huggingface.co/renjiepi/G-LLaVA-13B" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-03</td>
              <td><b>6.48%</b></td>
              <td>64.19% (337)</td>
              <td>4.57% (24)</td>
              <td>4.19% (22)</td>
              <td>86.59% (142)</td>
              <td><b>22.29%</b></td>
              <td>64.19% (337)</td>
              <td>4.57% (24)</td>
              <td>20.00% (105)</td>
              <td>35.98% (59)</td>
            </tr>
            <tr>
              <td>14</td>
              <td><b>DeepSeek-VL-7B</b></td>
              <td><a href="https://huggingface.co/deepseek-ai/deepseek-vl-7b-chat" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-03</td>
              <td><b>6.29%</b></td>
              <td>69.14% (363)</td>
              <td>4.57% (24)</td>
              <td>4.00% (21)</td>
              <td>84.78% (117)</td>
              <td><b>20.95%</b></td>
              <td>69.14% (363)</td>
              <td>4.57% (24)</td>
              <td>18.67% (98)</td>
              <td>28.99% (40)</td>
            </tr>
            <tr>
              <td>15</td>
              <td><b>DeepSeek-VL-1.3B</b></td>
              <td><a href="https://huggingface.co/deepseek-ai/deepseek-vl-1.3b-chat" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-03</td>
              <td><b>5.90%</b></td>
              <td>71.05% (373)</td>
              <td>2.67% (14)</td>
              <td>4.57% (24)</td>
              <td>82.61% (114)</td>
              <td><b>21.52%</b></td>
              <td>71.05% (373)</td>
              <td>2.67% (14)</td>
              <td>20.19% (106)</td>
              <td>23.19% (32)</td>
            </tr>
            <tr>
              <td>16</td>
              <td><b>LLaVA-1.6-13B</b></td>
              <td><a href="https://huggingface.co/liuhaotian/llava-v1.6-vicuna-13b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-03</td>
              <td><b>5.24%</b></td>
              <td>69.14% (363)</td>
              <td>3.24% (17)</td>
              <td>3.62% (19)</td>
              <td>86.90% (126)</td>
              <td><b>22.00%</b></td>
              <td>69.14% (363)</td>
              <td>3.24% (17)</td>
              <td>20.38% (107)</td>
              <td>26.21% (38)</td>
            </tr>
            <tr>
              <td>17</td>
              <td><b>LLaVA-1.6-7B</b></td>
              <td><a href="https://huggingface.co/liuhaotian/llava-v1.6-vicuna-7b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-03</td>
              <td><b>3.33%</b></td>
              <td>78.29% (411)</td>
              <td>2.48% (13)</td>
              <td>2.10% (11)</td>
              <td>89.11% (90)</td>
              <td><b>13.81%</b></td>
              <td>78.29% (411)</td>
              <td>2.48% (13)</td>
              <td>12.57% (66)</td>
              <td>34.65% (35)</td>
            </tr>
          </table>
          <table id="table2" class="js-sort-table hidden">
            <tr>
              <td class="js-sort-number"><strong>#</strong></td>
              <td class="js-sort"><strong>Model</strong></td>
              <td class="js-sort"><strong>Source</strong></td>
              <td class="js-sort-date"><strong>Date</strong></td>
              <td class="js-sort-number"><strong>S1</strong></td>
              <td class="js-sort-number"><strong>S2</strong></td>
              <td class="js-sort-number"><strong>S3</strong></td>
              <td class="js-sort-number"><strong>UCU(Mem)</strong></td>
              <td class="js-sort-number"><strong>AL(Mem)</strong></td>
              <td class="js-sort-number"><strong>CPF(PF)</strong></td>
              <td class="js-sort-number"><strong>UPF(PF)</strong></td>
              <td class="js-sort-number"><strong>CSF(SF)</strong></td>
              <td class="js-sort-number"><strong>USF(SF)</strong></td>
              <td class="js-sort-number"><strong>BTF(TMF)</strong></td>
              <td class="js-sort-number"><strong>CCF(TMF)</strong></td>
              <td class="js-sort-number"><strong>Dir(PD)</strong></td>
              <td class="js-sort-number"><strong>Pos(PD)</strong></td>
              <td class="js-sort-number"><strong>RoM(PD)</strong></td>
              <td class="js-sort-number"><strong>CCP(PD)</strong></td>
            </tr>
            <!--ÊîπÊàêÁôæÂàÜÊØî-->
            <tr>
              <td>1</td>
              <td><b>GPT-4o ü•á</b></td>
              <td><a href="https://openai.com/index/hello-gpt-4o/" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td>73.33%</td>
              <td>57.22%</td>
              <td>46.06%</td>
              <td>87.10%</td>
              <td>45.79%</td>
              <td>76.74%</td>
              <td>70.99%</td>
              <td>82.21%</td>
              <td>65.66%</td>
              <td>58.10%</td>
              <td>70.00%</td>
              <td>93.10%</td>
              <td>80.43%</td>
              <td>58.79%</td>
              <td>70.00%</td>
            </tr>
            <tr>
              <td>2</td>
              <td><b>GPT-4V ü•à</b></td>
              <td><a href="https://openai.com/contributions/gpt-4v/" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-04</td>
              <td>65.51%</td>
              <td>49.17%</td>
              <td>38.18%</td>
              <td>82.54%</td>
              <td>38.42%</td>
              <td>70.67%</td>
              <td>60.22%</td>
              <td>76.58%</td>
              <td>56.32%</td>
              <td>57.76%</td>
              <td>63.33%</td>
              <td>79.29%</td>
              <td>57.48%</td>
              <td>47.80%</td>
              <td>63.33%</td>
            </tr>
            <tr>
              <td>3</td>
              <td><b>Gemini-1.5-pro ü•â</b></td>
              <td><a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td>56.13%</td>
              <td>51.39%</td>
              <td>33.94%</td>
              <td>50.99%</td>
              <td>31.23%</td>
              <td>61.75%</td>
              <td>45.03%</td>
              <td>69.95%</td>
              <td>57.54%</td>
              <td>39.24%</td>
              <td>60.00%</td>
              <td>68.81%</td>
              <td>54.13%</td>
              <td>40.66%</td>
              <td>60.00%</td>
            </tr>
            <tr>
              <td>4</td>
              <td><b>LLaVA-NeXT-110B</b></td>
              <td><a href="https://huggingface.co/lmms-lab/llava-next-110b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td>53.74%</td>
              <td>36.94%</td>
              <td>31.52%</td>
              <td>39.48%</td>
              <td>57.72%</td>
              <td>59.48%</td>
              <td>53.06%</td>
              <td>52.25%</td>
              <td>50.22%</td>
              <td>54.09%</td>
              <td>40.00%</td>
              <td>54.76%</td>
              <td>55.86%</td>
              <td>40.11%</td>
              <td>40.00%</td>
            </tr>
            <tr>
              <td>5</td>
              <td><b>InternVL-Chat-V1.5</b></td>
              <td><a href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-04</td>
              <td>49.38%</td>
              <td>30.56%</td>
              <td>28.48%</td>
              <td>43.95%</td>
              <td>29.82%</td>
              <td>52.23%</td>
              <td>52.06%</td>
              <td>44.19%</td>
              <td>48.15%</td>
              <td>47.05%</td>
              <td>36.67%</td>
              <td>65.71%</td>
              <td>50.47%</td>
              <td>36.54%</td>
              <td>36.67%</td>
            </tr>
            <tr>
              <td>6</td>
              <td><b>GLM-4V-9B</b></td>
              <td><a href="https://huggingface.co/THUDM/glm-4v-9b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-06</td>
              <td>47.33%</td>
              <td>37.22%</td>
              <td>38.18%</td>
              <td>53.37%</td>
              <td>37.02%</td>
              <td>51.32%</td>
              <td>46.52%</td>
              <td>50.60%</td>
              <td>38.22%</td>
              <td>44.09%</td>
              <td>53.33%</td>
              <td>40.95%</td>
              <td>49.27%</td>
              <td>36.81%</td>
              <td>53.33%</td>
            </tr>
            <tr>
              <td>7</td>
              <td><b>LLaVA-NeXT-72B</b></td>
              <td><a href="https://huggingface.co/lmms-lab/llava-next-72b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td>42.88%</td>
              <td>35.56%</td>
              <td>30.91%</td>
              <td>31.65%</td>
              <td>25.26%</td>
              <td>43.25%</td>
              <td>42.39%</td>
              <td>46.14%</td>
              <td>41.76%</td>
              <td>44.22%</td>
              <td>36.67%</td>
              <td>44.29%</td>
              <td>38.93%</td>
              <td>32.97%</td>
              <td>36.67%</td>
            </tr>
            <tr>
              <td>8</td>
              <td><b>InternLM-XComposer2-VL-7B</b></td>
              <td><a href="https://huggingface.co/internlm/internlm-xcomposer2-vl-7b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-04</td>
              <td>47.00%</td>
              <td>33.06%</td>
              <td>33.33%</td>
              <td>31.25%</td>
              <td>46.49%</td>
              <td>47.70%</td>
              <td>42.57%</td>
              <td>51.44%</td>
              <td>43.87%</td>
              <td>41.13%</td>
              <td>40.00%</td>
              <td>65.48%</td>
              <td>53.87%</td>
              <td>55.22%</td>
              <td>40.00%</td>
            </tr>
            <tr>
              <td>9</td>
              <td><b>LongVA</b></td>
              <td><a href="https://huggingface.co/lmms-lab/LongVA-7B" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-06</td>
              <td>43.54%</td>
              <td>30.56%</td>
              <td>28.48%</td>
              <td>24.50%</td>
              <td>39.82%</td>
              <td>45.09%</td>
              <td>40.75%</td>
              <td>51.85%</td>
              <td>42.49%</td>
              <td>45.60%</td>
              <td>20.00%</td>
              <td>44.52%</td>
              <td>40.74%</td>
              <td>47.53%</td>
              <td>20.00%</td>
            </tr>
            <tr>
              <td>10</td>
              <td><b>Phi3-Vision-4.2B</b></td>
              <td><a href="https://huggingface.co/microsoft/Phi-3-vision-128k-instruct" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td>42.14%</td>
              <td>34.17%</td>
              <td>27.88%</td>
              <td>28.67%</td>
              <td>15.96%</td>
              <td>47.23%</td>
              <td>38.83%</td>
              <td>49.99%</td>
              <td>44.41%</td>
              <td>28.76%</td>
              <td>50.00%</td>
              <td>48.57%</td>
              <td>49.19%</td>
              <td>26.37%</td>
              <td>50.00%</td>
            </tr>
            <tr>
              <td>11</td>
              <td><b>Qwen-VL-Max</b></td>
              <td><a href="https://github.com/QwenLM/Qwen-VL/tree/master" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-01</td>
              <td>40.82%</td>
              <td>30.28%</td>
              <td>20.61%</td>
              <td>19.35%</td>
              <td>25.26%</td>
              <td>39.82%</td>
              <td>41.44%</td>
              <td>43.64%</td>
              <td>48.02%</td>
              <td>43.82%</td>
              <td>26.67%</td>
              <td>41.43%</td>
              <td>35.09%</td>
              <td>40.66%</td>
              <td>26.67%</td>
            </tr>
            <tr>
              <td>12</td>
              <td><b>MiniCPM-LLaMA3-V 2.5</b></td>
              <td><a href="https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-05</td>
              <td>39.75%</td>
              <td>31.11%</td>
              <td>29.70%</td>
              <td>28.57%</td>
              <td>37.02%</td>
              <td>40.81%</td>
              <td>39.82%</td>
              <td>40.97%</td>
              <td>38.61%</td>
              <td>31.96%</td>
              <td>43.33%</td>
              <td>40.95%</td>
              <td>42.70%</td>
              <td>43.96%</td>
              <td>43.33%</td>
            </tr>
            <tr>
              <td>13</td>
              <td><b>G-LLaVA-13B</b></td>
              <td><a href="https://huggingface.co/renjiepi/G-LLaVA-13B" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-03</td>
              <td>32.43%</td>
              <td>30.56%</td>
              <td>32.73%</td>
              <td>33.33%</td>
              <td>29.12%</td>
              <td>32.04%</td>
              <td>37.88%</td>
              <td>19.57%</td>
              <td>33.51%</td>
              <td>37.12%</td>
              <td>40.00%</td>
              <td>31.19%</td>
              <td>33.21%</td>
              <td>25.55%</td>
              <td>40.00%</td>
            </tr>
            <tr>
              <td>14</td>
              <td><b>DeepSeek-VL-7B</b></td>
              <td><a href="https://huggingface.co/deepseek-ai/deepseek-vl-7b-chat" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-03</td>
              <td>32.59%</td>
              <td>26.67%</td>
              <td>25.45%</td>
              <td>16.57%</td>
              <td>35.09%</td>
              <td>27.27%</td>
              <td>38.01%</td>
              <td>24.18%</td>
              <td>38.65%</td>
              <td>50.02%</td>
              <td>23.33%</td>
              <td>24.52%</td>
              <td>41.01%</td>
              <td>51.65%</td>
              <td>23.33%</td>
            </tr>
            <tr>
              <td>15</td>
              <td><b>DeepSeek-VL-1.3B</b></td>
              <td><a href="https://huggingface.co/deepseek-ai/deepseek-vl-1.3b-chat" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-03</td>
              <td>31.44%</td>
              <td>27.78%</td>
              <td>23.03%</td>
              <td>27.78%</td>
              <td>23.86%</td>
              <td>22.76%</td>
              <td>36.92%</td>
              <td>30.36%</td>
              <td>34.18%</td>
              <td>44.46%</td>
              <td>33.33%</td>
              <td>48.10%</td>
              <td>41.77%</td>
              <td>37.09%</td>
              <td>33.33%</td>
            </tr>
            <tr>
              <td>16</td>
              <td><b>LLaVA-1.6-13B</b></td>
              <td><a href="https://huggingface.co/liuhaotian/llava-v1.6-vicuna-13b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-03</td>
              <td>29.38%</td>
              <td>25.28%</td>
              <td>32.73%</td>
              <td>21.73%</td>
              <td>23.16%</td>
              <td>23.37%</td>
              <td>34.72%</td>
              <td>25.26%</td>
              <td>26.36%</td>
              <td>37.52%</td>
              <td>30.00%</td>
              <td>26.90%</td>
              <td>28.87%</td>
              <td>37.09%</td>
              <td>30.00%</td>
            </tr>
            <tr>
              <td>17</td>
              <td><b>LLaVA-1.6-7B</b></td>
              <td><a href="https://huggingface.co/liuhaotian/llava-v1.6-vicuna-7b" class="ext-link" style="font-size: 16px;">Link</a></td>
              <td>2024-03</td>
              <td>22.96%</td>
              <td>20.83%</td>
              <td>15.76%</td>
              <td>18.45%</td>
              <td>20.53%</td>
              <td>16.92%</td>
              <td>29.63%</td>
              <td>15.57%</td>
              <td>18.60%</td>
              <td>42.67%</td>
              <td>26.67%</td>
              <td>17.62%</td>
              <td>43.31%</td>
              <td>28.85%</td>
              <td>26.67%</td>
            </tr>
          </table>
          <div>
            <p>üö® To submit your results to the leaderboard, please send to <a href="mailto:qrq@bupt.edu.cn">this email</a> with your result json files.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section>        
  <div class="container">
    <div class="columns is-centered has-text-centered m-6">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results on Existing Foundation Models</h2>
        <div class="content has-text-justified">
          <!--img show case-->
          <div id="results-carousel" class="carousel results-carousel">
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/fig6-3leida_res.png" width="90%"/>
                <p> The visualization of different LMMs' performances on each category.</p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/fig8_strict.png" width="90%"/>
                <p> The performance of different LMMs on four-dimensional metrics under strict metric. </p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/fig9_loose.png" width="90%"/>
                <p> The performance of different LMMs on four-dimensional metrics under loose metric. </p>
              </div>
            </div>
            <div class="box m-5">
              <div class="content has-text-centered">
                <img src="static/images/Leaderboard.png" width="90%"/>
                <p> The Leaderboard of different LMMs under the strict and loose metric (average score %). 
                  ~ represents an approximate estimate of the total parameters nums in LMMs. </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!--knowledge card-->
<section>
  <div class="container">
    <div class="columns is-centered has-text-centered m-6">
      <div class="column is-four-fifths">
        <h2 class="title is-3" id="examples">Knowledge Card</h2>
        <div class="content has-text-justified">
          <!--img show case-->
          <div id="results-carousel" class="carousel results-carousel">
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card1_res.png" width="80%"/>
                <p> The description of the knowledge concept "Angles and Length". </p>
              </div>
            </div>
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card2_res.png" width="80%"/>
                <p> The description of the knowledge concept "Correspondence of Coordinates and Positions". </p>
              </div>
            </div>
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card3_res.png" width="80%"/>
                <p> The description of the knowledge concept "Basic Transformations of Figures". </p>
              </div>
            </div>
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card4_res.png" width="80%"/>
                <p> The description of the knowledge concept "Cutting and Combining of Figures". </p>
              </div>
            </div>
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card5_res.png" width="80%"/>
                <p> The description of the knowledge concepts "Direction" and "Position". </p>
              </div>
            </div>
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card8_res.png" width="80%"/>
                <p> The description of the knowledge concept "Route Map". </p>
              </div>
            </div>
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card9_res.png" width="80%"/>
                <p> The description of the knowledge concept "Understanding and Conversion of Units". </p>
              </div>
            </div>
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card6_res.png" width="80%"/>
                <p> The description of the knowledge concept "Calculation of Solid Figures". </p>
              </div>
            </div>
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card7_res.png" width="80%"/>
                <p> The description of the knowledge concept "Calculation of Plane Figures". </p>
              </div>
            </div>
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card10_res.png" width="80%"/>
                <p> The description of the knowledge concept "Understanding of Plane Figures". </p>
              </div>
            </div>
            <div class="box m-5" style="height: 100%; display: flex; justify-content: center; align-items: center; text-align: center;">
              <div class="content has-text-centered">
                <img src="static/images/card11_res.png" width="80%"/>
                <p> The description of the knowledge concept "Understanding of Solid Figures". </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-----------------------------------------------ÁªìÊùüÈÉ®ÂàÜ------------------------------------------------------>
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{qiao2024wemathdoeslargemultimodal,
      title={We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?}, 
      author={Runqi Qiao and Qiuna Tan and Guanting Dong and Minhui Wu and Chong Sun and Xiaoshuai Song and Zhuoma GongQue and Shanglin Lei and Zhe Wei and Miaoxuan Zhang and Runfeng Qiao and Yifan Zhang and Xiao Zong and Yida Xu and Muxi Diao and Zhimin Bao and Chen Li and Honggang Zhang},
      year={2024},
      eprint={2407.01284},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.01284}, 
}</code></pre>
  </div>
</section>


<!--logo-->
<!--
<section>
  <div class="section" id="org-banners" style="display:flex">
    <a href="https://www.bupt.edu.cn/" target="_blank" rel="external">
        <img class="center-block org-banner" src="static/images/BUPT.png">
    </a>
    <a href="https://www.bupt.edu.cn/" target="blank" class="ext-link">
        <img class="center-block org-banner" src="static/images/PRIS.png">
    </a>
    <a href="https://www.bupt.edu.cn/" target="blank" class="ext-link">
        <img class="center-block org-banner" src="static/images/tencent_logo.png">
    </a>
    <a href="https://www.bupt.edu.cn/" target="_blank" rel="external">
        <img class="center-block org-banner" src="static/images/wechat_logo.png">
    </a>
  </div>
</section>-->



<!--footer-->
<footer class="footer">
  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">
        <p>
          This website is adapted from <a href="https://nerfies.github.io/">Nerfies</a> and <a href="https://mathvista.github.io/">MathVista</a>, licensed under a <a rel="license"
                                              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
          Commons Attribution-ShareAlike 4.0 International License</a>.
        </p>
      </div>
    </div>
  </div>
</footer>
<!-----------------end body---------------------->

</body>
</html>
